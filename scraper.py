
import streamlit as st
import requests
import pandas as pd
from bs4 import BeautifulSoup

# The base URL for the pages to be scraped
BASE_URL = "https://ssr1.scrape.center"
# The number of pages to scrape
TOTAL_PAGES = 10

def scrape_page(url):
    """Scrapes a single page and returns a list of movie data."""
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()  # Raise an exception for bad status codes
        soup = BeautifulSoup(response.text, 'html.parser')
        
        movies = []
        movie_items = soup.find_all('div', class_='el-card item m-t is-hover-shadow')

        for item in movie_items:
            title_tag = item.find('h2', class_='m-b-sm')
            title = title_tag.text.strip() if title_tag else 'N/A'

            img_tag = item.find('img', class_='cover')
            image_url = img_tag['src'] if img_tag else 'N/A'

            rating_tag = item.find('p', class_='score')
            rating = rating_tag.text.strip() if rating_tag else 'N/A'

            genres_div = item.find('div', class_='categories')
            genres = [span.text.strip() for span in genres_div.find_all('span')] if genres_div else []
            genres_str = ', '.join(genres)

            movies.append({
                'title': title,
                'image_url': image_url,
                'rating': rating,
                'genres': genres_str
            })
        return movies
    except requests.RequestException as e:
        st.error(f"Error fetching {url}: {e}")
        return []

def main():
    """Main function to build the Streamlit UI."""
    st.title('ğŸ¬ ç”µå½±æ•°æ®çˆ¬è™«')
    st.write(f"æ­¤åº”ç”¨å°†ä» `{BASE_URL}` ç½‘ç«™çˆ¬å–å‰ {TOTAL_PAGES} é¡µçš„ç”µå½±æ•°æ®ã€‚")

    if st.button('ğŸš€ å¼€å§‹çˆ¬å–æ•°æ®'):
        all_movies = []
        progress_bar = st.progress(0)
        status_text = st.empty()

        with st.spinner('æ­£åœ¨çˆ¬å–ä¸­... è¯·ç¨å€™...'):
            for page in range(1, TOTAL_PAGES + 1):
                url = f"{BASE_URL}/page/{page}"
                status_text.text(f"æ­£åœ¨çˆ¬å–ç¬¬ {page}/{TOTAL_PAGES} é¡µ...")
                movies_on_page = scrape_page(url)
                all_movies.extend(movies_on_page)
                progress_bar.progress(page / TOTAL_PAGES)
        
        status_text.text('') # Clear status text
        st.success(f'âœ… çˆ¬å–å®Œæˆï¼å…±æ‰¾åˆ° {len(all_movies)} éƒ¨ç”µå½±ã€‚')

        if all_movies:
            df = pd.DataFrame(all_movies)
            
            st.subheader('ç”µå½±æ•°æ®è¡¨æ ¼')
            st.dataframe(df)

            st.subheader('ç”µå½±æµ·æŠ¥å¢™')
            # Display images in columns
            cols = st.columns(5) 
            for index, row in df.iterrows():
                with cols[index % 5]:
                    st.image(row['image_url'], caption=f"{row['title']} ({row['rating']})", use_column_width=True)

if __name__ == '__main__':
    main()
